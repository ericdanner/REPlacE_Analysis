{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import itertools\n",
    "import operator\n",
    "import subprocess\n",
    "import twobitreader\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pysam\n",
    "\n",
    "#not sure if I need these\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for exceptions in this module.\"\"\"\n",
    "    pass\n",
    "\n",
    "class StrandError(Error):\n",
    "    \"\"\"Exception raised for errors in the strand information.\n",
    "    Attributes:\n",
    "        expression -- input expression in which the error occurred\n",
    "        message -- explanation of the error\n",
    "    \"\"\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "class ReactionTypeError(Error):\n",
    "    \"\"\"Exception raised for errors in the reaction type to be processed.\n",
    "    Attributes:\n",
    "        expression -- input expression in which the error occurred\n",
    "        message -- explanation of the error\n",
    "    \"\"\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are copied and unchanged from the Uditas v1 software\n",
    "\n",
    "################################################################################\n",
    "# Open .fastq or .fastq.gz files for reading\n",
    "################################################################################\n",
    "def open_fastq_or_gz(filename):\n",
    "    if filename.endswith(\".fastq\") and os.access(filename, os.F_OK):\n",
    "        return open(filename, \"rU\")\n",
    "    elif filename.endswith(\".fastq.gz\") and os.access(filename, os.F_OK):\n",
    "        return gzip.open(filename, \"rb\")\n",
    "    elif filename.endswith(\".fastq\") and os.access(filename + \".gz\", os.F_OK):\n",
    "        return gzip.open(filename + \".gz\", \"rb\")\n",
    "    elif filename.endswith(\".fastq.gz\") and os.access(filename[:-3], os.F_OK):\n",
    "        return open(filename[:-3], \"rU\")\n",
    "    raise IOError(\"Unknown file: \" + filename)\n",
    "\n",
    "################################################################################\n",
    "# Hamming distance\n",
    "# From http://code.activestate.com/recipes/499304-hamming-distance/\n",
    "################################################################################\n",
    "def hamm_dist(str1, str2):\n",
    "    assert len(str1) == len(str2)\n",
    "    ne = operator.ne\n",
    "    return sum(itertools.imap(ne, str1, str2))\n",
    "\n",
    "################################################################################\n",
    "# Select closest barcode with a maximum number of mismatches\n",
    "# By default it returns barcodes with a maximum of n_max_mismatches=2 mismatches\n",
    "################################################################################\n",
    "def select_barcode(seq, barcode_list, n_max_mismatches=1):\n",
    "    # This compares with all barcodes and selects the one with the smallest hamming distance\n",
    "    # Before calling this function check if the sequence is already a barcode\n",
    "    matched_barcodes = list()\n",
    "    distances = list()\n",
    "    for barcode in barcode_list:\n",
    "        h_d = hamm_dist(seq, barcode)\n",
    "        if h_d <= n_max_mismatches:\n",
    "            matched_barcodes.append(barcode)\n",
    "            distances.append(h_d)\n",
    "    indices = [i for i, x in enumerate(distances) if x == min(distances)]\n",
    "    return [matched_barcodes[i] for i in indices]\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Mask sequence by quality score\n",
    "################################################################################\n",
    "def mask(seq, qual, min_qual=12):\n",
    "\n",
    "    return \"\".join((b if (ord(q) - 33) >= min_qual else \"N\") for b, q in itertools.izip(seq, qual))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# get the reverse-complement DNA sequence\n",
    "################################################################################\n",
    "def reverse_complement(seq):\n",
    "    seq_dict = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G', 'N': 'N', 'a': 't', 't': 'a', 'g': 'c', 'c': 'g'}\n",
    "    return \"\".join([seq_dict[base] for base in reversed(seq)])\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Create umi dict\n",
    "################################################################################\n",
    "def create_umi_dict(filename):\n",
    "\n",
    "    umi_file = open_fastq_or_gz(filename)\n",
    "\n",
    "    umi_dict = dict()\n",
    "\n",
    "    umi_reads = itertools.izip(umi_file)\n",
    "\n",
    "    for header_umi in umi_reads:\n",
    "\n",
    "        seq_umi = umi_reads.next()\n",
    "        umi_reads.next()\n",
    "        qual_umi = umi_reads.next()\n",
    "        umi_dict[header_umi[0].split()[0][1:]] = [seq_umi[0].rstrip(), qual_umi[0].rstrip()]\n",
    "\n",
    "    return umi_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################\n",
    "# create list of output files\n",
    "#I added a bit to allow for the function that makes a fastq of the correctly primed targets\n",
    "################################################################################\n",
    "def create_filename(dir_sample, N7, N5, filetype):\n",
    "    main_folder = os.path.join(dir_sample, N7 + '_' + N5)\n",
    "    if filetype == 'mainfolder':\n",
    "        return main_folder\n",
    "    elif filetype == 'amplicons':\n",
    "        return os.path.join(main_folder, 'amplicons')\n",
    "    elif filetype == 'R1fastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.fastq')\n",
    "    elif filetype == 'R1fastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.fastq.gz')\n",
    "    elif filetype == 'R2fastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.fastq')\n",
    "    elif filetype == 'R2fastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.fastq.gz')\n",
    "   \n",
    "    #### I added these as the sequences that were correctly primed\n",
    "    elif filetype == 'R1fastq_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.CorrPrime.fastq')\n",
    "    elif filetype == 'R1fastqgz_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.CorrPrime.fastq.gz')\n",
    "    elif filetype == 'R2fastq_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.CorrPrime.fastq')\n",
    "    elif filetype == 'R2fastqgz_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.CorrPrime.fastq.gz')\n",
    "    #####\n",
    "    \n",
    "    elif filetype == 'umifastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_umi.fastq')\n",
    "    elif filetype == 'umifastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_umi.fastq.gz')\n",
    "    elif filetype == 'R1trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R1.trimmed.fastq.gz')\n",
    "    elif filetype == 'R2trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R2.trimmed.fastq.gz')\n",
    "    elif filetype == 'trimmed_report':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '.trimmed.report.txt')\n",
    "    elif filetype == 'sam_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'sam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_qsorted_unmapped.bam')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'sam_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_amplicons_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_qsorted_amplicons_unmapped.bam')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_report':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '.unmapped.report.txt')\n",
    "    elif filetype == 'sam_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'results_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5)  # We will append the window size later\n",
    "    elif filetype == 'results_plasmid':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_plasmid.xlsx')\n",
    "    elif filetype == 'results_all_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_all_amplicons.xlsx')\n",
    "    elif filetype == 'results_genomewide':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_genomewide.xlsx')\n",
    "    elif filetype == 'summary_all_alignments':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_summary_all_alignments.xlsx')\n",
    "    elif filetype == 'read_counts':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_read_counts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only\n"
     ]
    }
   ],
   "source": [
    "#Directory\n",
    "directory = '/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only'\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only/10000Reads\n"
     ]
    }
   ],
   "source": [
    "#Directory minimal files\n",
    "directory10000 = '/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only/10000Reads'\n",
    "print(directory10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to take the line of the excel information of interst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make the 'amplicon_info' list. Taking the line of our experiment csv file\n",
    "\n",
    "def get_csv_data(dir_sample, line_of_data_from_csv):\n",
    "    sample_info_filename = os.path.join(dir_sample, 'sample_info.csv')\n",
    "    experiments = pd.read_csv(sample_info_filename)\n",
    "    return experiments.loc[line_of_data_from_csv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the amplicon info is related to the line on the csv file. It is indexed from 0. For PolbF we use 0.\n",
    "amplicon_info10000 = get_csv_data(directory10000, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard Mispriming Reads\n",
    "When you put a universal primer on the ends of everything, every mispriming event will amplify. An effect we normally don't deal with. I did nested PCR to reduce this. However 85% of the alignments in the UDITAS data I looked at seemed to be mispriming. They did all their blasting and analysis before removing mispriming. But to save computational power and remove error early on I will discard mispriming events. \n",
    "They discard these only for plasmid alignments analyze_alignments_plasmid for some reason which comes from the bam file.\n",
    "\n",
    "By eye it looks like 50-90% of my reads are correctly primed which is amaizng. Nesting helepd a lot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my homemade function to make a fastq with only correct priming events\n",
    "#I currently have skipped making this becasue a relitivly high amount are on target due to nested and I just want results\n",
    "def correct_priming(dir_sample, N7, N5):\n",
    "    \n",
    "\n",
    "r1_fastq = os.path.join(dir_sample, 'Undetermined_S0_R1_001.fastq.gz')\n",
    "r2_fastq = os.path.join(dir_sample, 'Undetermined_S0_R2_001.fastq.gz')\n",
    "\n",
    "files_out.append(create_filename(dir_sample, N7, N5, 'R1fastq_CorrPrime'))\n",
    "files_out.append(create_filename(dir_sample, N7, N5, 'R2fastq_CorrPrime'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#\n",
    "# Remove adapters in fastq files. The idea of this is that if the sequence runs beyond the length of the acutal genomice sequence into the sequencing\n",
    "#       primers on the other other side, it will then be trimmed down so you dont try and align adapter sequences. \n",
    "# Input: directory to be analyzed (fastq files)\n",
    "#        dir_sample, name of the directory for the whole run, typically with the name of a miseq run\n",
    "#        amplicon_info, slice of sample_info.csv for the sample being processed to get the indexes required for saving names\n",
    "#        process_AMP_seq_run, set to 1 to trim in read2 the same adapter as in GUIDE-Seq\n",
    "     # it is very important! to pay attention to if youre using the nextera or trueseq adapters as the sequence to trim will be different on the i7 side.\n",
    "#\n",
    "\n",
    "#\n",
    "# ##########################\n",
    "def trim_fastq(dir_sample, amplicon_info, process_AMP_seq_run):\n",
    "\n",
    "    # UDiTaS adapters\n",
    "    Nv2F = 'TCGTCGGCAGCGTCAGATGTGTATAAGAGACAG' #for the i5 side\n",
    "    SBS12nextera = 'GTCTCGTGGGCTCGGAGATGTGTATAAGAGACAG'  #this is for the i7 side for nextera\n",
    "  #  SBS12 = 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'  #this is for i7 side for trueseq primers **need this one for the pytest**\n",
    "\n",
    "    if process_AMP_seq_run == 1:\n",
    "        i2_adapter = 'ACACTCTTTCCCTACACGACGCTCTTCCGATCT'\n",
    "    else:\n",
    "        i2_adapter = Nv2F\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    file_R1 = create_filename(dir_sample, N7, N5, 'R1fastqgz')\n",
    "    file_R2 = create_filename(dir_sample, N7, N5, 'R2fastqgz')\n",
    "\n",
    "    file_cutadapt_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "    file_cutadapt_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "    file_cutadapt_report = create_filename(dir_sample, N7, N5, 'trimmed_report')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_cutadapt_R1)):\n",
    "        os.mkdir(os.path.dirname(file_cutadapt_R1))\n",
    "\n",
    "    # remove adapters with cutadapt\n",
    "    #original uditas peramiter had an error -e 0.33 (but was cutting of random stuff too much)\n",
    "    cutadapt_command = ['cutadapt',\n",
    "                        '-m', '10',\n",
    "                        '-e', '0.25',\n",
    "                        '-a', reverse_complement(SBS12nextera),\n",
    "                        '-A', reverse_complement(i2_adapter),\n",
    "                        '-o', file_cutadapt_R1, '-p', file_cutadapt_R2,\n",
    "                        file_R1, file_R2]\n",
    "\n",
    "    handle_cutadapt_report = open(file_cutadapt_report, 'wb')\n",
    "    subprocess.call(cutadapt_command, stdout=handle_cutadapt_report)\n",
    "    handle_cutadapt_report.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the trimming\n",
    "\n",
    "trim_fastq(directory10000, amplicon_info10000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Function to write reference plasmid sequence\n",
    "################################################\n",
    "def create_plasmid_reference(dir_sample, amplicon_info):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "    amplicon_folder = os.path.join(exp_dir, 'amplicons')\n",
    "    if not os.path.exists(amplicon_folder):\n",
    "        os.mkdir(amplicon_folder)\n",
    "\n",
    "    filename = os.path.join(exp_dir, amplicon_folder, 'plasmid.fa')\n",
    "    file_handle = open(filename, \"w\")\n",
    "\n",
    "    # If several plasmids were given, separate them using ';' in sample_info.csv. Here we remove the ';' so that\n",
    "    # we just concatenate the sequences\n",
    "    pl_seq = amplicon_info['plasmid_sequence'].replace(';', '')\n",
    "    seq1 = Seq(pl_seq, IUPAC.unambiguous_dna)\n",
    "    record1 = SeqRecord(seq1, 'plasmid', description='')\n",
    "    SeqIO.write(record1, file_handle, 'fasta')\n",
    "\n",
    "    file_handle.close()\n",
    "    # Create index file\n",
    "    initial_dir = os.getcwd()\n",
    "    os.chdir(amplicon_folder)\n",
    "    index_err_file = os.path.join(amplicon_folder, 'index_plasmid.err')\n",
    "    index_out_file = os.path.join(amplicon_folder, 'index_plasmid.out')\n",
    "\n",
    "    index_err_fh = open(index_err_file, 'wb')\n",
    "    index_out_fh = open(index_out_file, 'wb')\n",
    "    subprocess.call(['bowtie2-build',\n",
    "                     filename, 'plasmid'], stderr=index_err_fh, stdout=index_out_fh)\n",
    "    os.chdir(initial_dir)\n",
    "    index_err_fh.close()\n",
    "    index_out_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the reference plasmid creation\n",
    "create_plasmid_reference(directory10000, amplicon_info10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set global variables\n",
    "export BOWTIE2_INDEXES=/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes\n",
    "export GENOMES_2BIT=/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes\n",
    "\n",
    "check:\n",
    "> echo $BOWTIE2_INDEXES\n",
    "> echo $GENOMES_2BIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ############################\n",
    "    #\n",
    "    #  Function to determine the kind of reaction from the number of cuts and their locations\n",
    "    # I changed this to add the replace option\n",
    "    #\n",
    "    # The function classify the cases:\n",
    "    #   - No cut (just UDiTaS primer, used for controls)\n",
    "    #   - Single cut\n",
    "    #   - Replace (has to come before duel cut in logic order)\n",
    "    #   - Dual cut on same chromosome, generates amplicons with large deletions, etc\n",
    "    #   - Dual cut on different chromosomes. Generates 10 amplicons including translocations\n",
    "    #   - Triple cuts on different chromosomes. Generates 21 amplicons including translocations. NOTE that if two of the\n",
    "    #     cuts are in the same chromosome and close together (less than amplicon_window_around_cut) the results may\n",
    "    #     be incorrect since some reads may be mapped to multiple amplicons, but only counted around the cut in one amplicon\n",
    "    #\n",
    "    ############################\n",
    "    def get_reaction_type(amplicon_info):\n",
    "        has_guide1 = type(amplicon_info['chr_guide_1']) is str or type(amplicon_info['chr_guide_1']) is unicode\n",
    "        has_guide2 = type(amplicon_info['chr_guide_2']) is str or type(amplicon_info['chr_guide_2']) is unicode\n",
    "        has_guide3 = type(amplicon_info['chr_guide_3']) is str or type(amplicon_info['chr_guide_3']) is unicode\n",
    "        has_replace_donor = type(amplicon_info['Replace_Donor']) is str or type(amplicon_info['Replace_Donor']) is unicode\n",
    "    \n",
    "        if not has_guide1 and not has_guide2 and not has_guide3:\n",
    "            reaction_type = 'control'\n",
    "        elif has_guide1 and not has_guide2 and not has_guide3:\n",
    "            reaction_type = 'single_cut'\n",
    "         #this is the modification of the origianl. It shows if we are doing a replace targeting\n",
    "        elif has_guide1 and has_guide2 and amplicon_info['chr_guide_1'] == amplicon_info['chr_guide_2'] and has_replace_donor:\n",
    "            reaction_type = 'replace' \n",
    "        \n",
    "        elif has_guide1 and has_guide2 and amplicon_info['chr_guide_1'] == amplicon_info['chr_guide_2'] and not has_guide3:\n",
    "            reaction_type = 'double_cut_same_chromosome'      \n",
    "        elif has_guide1 and has_guide2 and amplicon_info['chr_guide_1'] != amplicon_info['chr_guide_2'] and not has_guide3:\n",
    "            reaction_type = 'double_cut_different_chromosomes'\n",
    "        elif has_guide1 and has_guide2 and has_guide3:\n",
    "            if (amplicon_info['chr_guide_1'] == amplicon_info['chr_guide_2'] or\n",
    "                    amplicon_info['chr_guide_1'] == amplicon_info['chr_guide_3'] or\n",
    "                    amplicon_info['chr_guide_2'] == amplicon_info['chr_guide_3']):\n",
    "                raise ReactionTypeError('The reaction with three cuts with at least two in the same chromosome is' +\n",
    "                                        ' not yet supported by current version of UDiTaS')\n",
    "            reaction_type = 'triple_cut_different_chromosomes'\n",
    "        else:\n",
    "            raise ReactionTypeError('Reaction type not yet supported by current version of UDiTaS')\n",
    "    \n",
    "        return reaction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Replace'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the get_reaction_type is working\n",
    "get_reaction_type(amplicon_info10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################################################################\n",
    "# Function to write reference amplicons with various structural rearrangements\n",
    "#################################################################################\n",
    "def write_amplicon(dir_sample, amplicon_info, amplicon_list):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "    amplicon_folder = os.path.join(exp_dir, 'amplicons')\n",
    "    if not os.path.exists(amplicon_folder):\n",
    "        os.mkdir(amplicon_folder)\n",
    "\n",
    "    filename = os.path.join(exp_dir, amplicon_folder, 'amplicons.fa')\n",
    "    file_handle = open(filename, \"w\")\n",
    "\n",
    "    for amps in amplicon_list:\n",
    "        seq1 = Seq(amps[1], IUPAC.unambiguous_dna)\n",
    "        record1 = SeqRecord(seq1, amps[0], description='')\n",
    "        SeqIO.write(record1, file_handle, 'fasta')\n",
    "\n",
    "    file_handle.close()\n",
    "    # Create index file\n",
    "    initial_dir = os.getcwd()\n",
    "    os.chdir(amplicon_folder)\n",
    "    index_err_file = os.path.join(amplicon_folder, 'index.err')\n",
    "    index_out_file = os.path.join(amplicon_folder, 'index.out')\n",
    "\n",
    "    index_err_fh = open(index_err_file, 'wb')\n",
    "    index_out_fh = open(index_out_file, 'wb')\n",
    "    subprocess.call(['bowtie2-build',\n",
    "                     filename, 'amplicons'], stderr=index_err_fh, stdout=index_out_fh)\n",
    "    os.chdir(initial_dir)\n",
    "    index_err_fh.close()\n",
    "    index_out_fh.close()\n",
    "\n",
    "############################\n",
    "#\n",
    "# Create amplicon. Creates fasta file with the custom reference amplicons including deletions, inversions, etc...\n",
    "#\n",
    "# Input: dir_sample, directory to be analyzed\n",
    "#        amplicon_info, slice of sample_info.csv for the sample being processed\n",
    "#        file_genome_2bit, 2bit file with the reference genome being used\n",
    "#        amplicon_window_around_cut, value used to grab sequences around cut sites\n",
    "#\n",
    "#   This functions creates a set of reference amplicons built from the expected fragments after cutting\n",
    "#   The amplicons are built differently depending on the case classified by get_reaction_type()\n",
    "#\n",
    "# ##########################\n",
    "def create_amplicon(dir_sample, amplicon_info, file_genome_2bit, amplicon_window_around_cut=1000):\n",
    "    # We first check the reaction type\n",
    "    reaction_type = get_reaction_type(amplicon_info)\n",
    "\n",
    "    genome = twobitreader.TwoBitFile(file_genome_2bit)  # Load genome. Used for getting the sequences\n",
    "\n",
    "    amplicon_list = []\n",
    "\n",
    "    # For all reaction types, we check that we don't go out of boundaries when building the amplicons\n",
    "    # This is unlikely for hg38 or mm10, but could easily happen in the UDiTaS primer is in a plasmid\n",
    "    if reaction_type == 'control':\n",
    "        # Case no guides\n",
    "        if amplicon_info['strand'] == '+':  # This is the UDiTaS oligo strand\n",
    "            end_coordinate = int(amplicon_info['start']) + amplicon_window_around_cut\n",
    "            if end_coordinate > len(genome[amplicon_info['chr']]):\n",
    "                end_coordinate = len(genome[amplicon_info['chr']])\n",
    "            amplicon_list.append(['wt', genome[amplicon_info['chr']][int(amplicon_info['start']):end_coordinate]])\n",
    "        elif amplicon_info['strand'] == '-':\n",
    "            start_coordinate = int(amplicon_info['end']) - amplicon_window_around_cut\n",
    "            if start_coordinate < 0:\n",
    "                start_coordinate = 0\n",
    "            amplicon_list.append(['wt', genome[amplicon_info['chr']][start_coordinate:int(amplicon_info['end'])]])\n",
    "        else:\n",
    "            raise StrandError('strand can only have as values + or -')\n",
    "    elif reaction_type == 'single_cut':\n",
    "        # Case one guide\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        start_coordinate = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate < 0:\n",
    "            start_coordinate = 0\n",
    "        end_coordinate = int(cut1 + amplicon_window_around_cut)\n",
    "        if end_coordinate > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        seq_upstream = genome[amplicon_info['chr_guide_1']][start_coordinate:int(cut1)]\n",
    "        seq_downstream = genome[amplicon_info['chr_guide_1']][int(cut1):end_coordinate]\n",
    "\n",
    "        amplicon_list.append(['wt', seq_upstream + seq_downstream])\n",
    "        amplicon_list.append(['1a_1a', seq_upstream + reverse_complement(seq_upstream)])\n",
    "        amplicon_list.append(['1b_1b', reverse_complement(seq_downstream) + seq_downstream])\n",
    "    elif reaction_type == 'double_cut_same_chromosome':\n",
    "        # Case two guides on the same chromosome\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        # We switch the coordinates of cut1 and cut2 if the guides are provided so that cut2 < cut1\n",
    "        # cut1 it will always be smaller than cut2 and in the results cut1 will be the cut site with\n",
    "        # smaller genomic coordinate\n",
    "        # cut1 and cut2 also flipped in get_cut_in_reference_amplicon_df\n",
    "\n",
    "        if cut2 < cut1:\n",
    "            (cut1, cut2) = (cut2, cut1)\n",
    "\n",
    "        start_coordinate = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate < 0:\n",
    "            start_coordinate = 0\n",
    "        end_coordinate = int(cut2 + amplicon_window_around_cut)\n",
    "        if end_coordinate > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        seq_upstream = genome[amplicon_info['chr_guide_1']][start_coordinate:int(cut1)]\n",
    "        seq_cut1_cut2 = genome[amplicon_info['chr_guide_1']][int(cut1):int(cut2)]\n",
    "        seq_downstream = genome[amplicon_info['chr_guide_1']][int(cut2):end_coordinate]\n",
    "\n",
    "        amplicon_list.append(['wt', seq_upstream + seq_cut1_cut2 + seq_downstream])\n",
    "        amplicon_list.append(['large_deletion', seq_upstream + seq_downstream])\n",
    "        amplicon_list.append(['large_inversion', seq_upstream + reverse_complement(seq_cut1_cut2) + seq_downstream])\n",
    "        amplicon_list.append(['1a_1a', seq_upstream + reverse_complement(seq_upstream)])\n",
    "        amplicon_list.append(['2b_2b', reverse_complement(seq_downstream) + seq_downstream])\n",
    "    \n",
    "    #added this modification from Uditas for replace\n",
    "    elif reaction_type == 'replace':\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        # We switch the coordinates of cut1 and cut2 if the guides are provided so that cut2 < cut1\n",
    "        # cut1 it will always be smaller than cut2 and in the results cut1 will be the cut site with\n",
    "        # smaller genomic coordinate\n",
    "        # cut1 and cut2 also flipped in get_cut_in_reference_amplicon_df\n",
    "\n",
    "        if cut2 < cut1:\n",
    "            (cut1, cut2) = (cut2, cut1)\n",
    "\n",
    "        start_coordinate = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate < 0:\n",
    "            start_coordinate = 0\n",
    "        end_coordinate = int(cut2 + amplicon_window_around_cut)\n",
    "        if end_coordinate > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        seq_upstream = genome[amplicon_info['chr_guide_1']][start_coordinate:int(cut1)]\n",
    "        seq_cut1_cut2 = genome[amplicon_info['chr_guide_1']][int(cut1):int(cut2)]\n",
    "        seq_downstream = genome[amplicon_info['chr_guide_1']][int(cut2):end_coordinate]\n",
    "\n",
    "        amplicon_list.append(['wt', seq_upstream + seq_cut1_cut2 + seq_downstream])\n",
    "        amplicon_list.append(['large_deletion', seq_upstream + seq_downstream])\n",
    "        amplicon_list.append(['large_inversion', seq_upstream + reverse_complement(seq_cut1_cut2) + seq_downstream])\n",
    "        amplicon_list.append(['replace_fwd', seq_upstream + amplicon_info['Replace_Donor'] + seq_downstream])\n",
    "        amplicon_list.append(['replace_rev', seq_upstream + reverse_complement(amplicon_info['Replace_Donor']) + seq_downstream])\n",
    "        amplicon_list.append(['doner_tail_tail', amplicon_info['Replace_Donor'] + reverse_complement(amplicon_info['Replace_Donor'])])\n",
    "        amplicon_list.append(['doner_head_tail', amplicon_info['Replace_Donor'] + amplicon_info['Replace_Donor']])\n",
    "        amplicon_list.append(['doner_head_head', reverse_complement(amplicon_info['Replace_Donor']) + amplicon_info['Replace_Donor']])      \n",
    "        amplicon_list.append(['1a_1a', seq_upstream + reverse_complement(seq_upstream)])\n",
    "        amplicon_list.append(['2b_2b', reverse_complement(seq_downstream) + seq_downstream])\n",
    "        \n",
    "        \n",
    "    elif reaction_type == 'double_cut_different_chromosomes':\n",
    "        # Case two guides on different chromosomes\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        start_coordinate1 = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate1 < 0:\n",
    "            start_coordinate1 = 0\n",
    "        end_coordinate1 = int(cut1 + amplicon_window_around_cut)\n",
    "        if end_coordinate1 > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate1 = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        start_coordinate2 = int(cut2 - amplicon_window_around_cut)\n",
    "        if start_coordinate2 < 0:\n",
    "            start_coordinate2 = 0\n",
    "        end_coordinate2 = int(cut2 + amplicon_window_around_cut)\n",
    "        if end_coordinate2 > len(genome[amplicon_info['chr_guide_2']]):\n",
    "            end_coordinate2 = len(genome[amplicon_info['chr_guide_2']])\n",
    "\n",
    "        seq_1a = genome[amplicon_info['chr_guide_1']][start_coordinate1:int(cut1)]\n",
    "        seq_1b = genome[amplicon_info['chr_guide_1']][int(cut1):end_coordinate1]\n",
    "        seq_2a = genome[amplicon_info['chr_guide_2']][start_coordinate2:int(cut2)]\n",
    "        seq_2b = genome[amplicon_info['chr_guide_2']][int(cut2):end_coordinate2]\n",
    "\n",
    "        amplicon_list.append(['1a_1a', seq_1a + reverse_complement(seq_1a)])\n",
    "        amplicon_list.append(['1a_1b', seq_1a + seq_1b])\n",
    "        amplicon_list.append(['1a_2a', seq_1a + reverse_complement(seq_2a)])\n",
    "        amplicon_list.append(['1a_2b', seq_1a + seq_2b])\n",
    "\n",
    "        amplicon_list.append(['1b_1b', reverse_complement(seq_1b) + seq_1b])\n",
    "        amplicon_list.append(['2a_1b', seq_2a + seq_1b])\n",
    "        amplicon_list.append(['2b_1b', reverse_complement(seq_2b) + seq_1b])\n",
    "\n",
    "        amplicon_list.append(['2a_2a', seq_2a + reverse_complement(seq_2a)])\n",
    "        amplicon_list.append(['2a_2b', seq_2a + seq_2b])\n",
    "\n",
    "        amplicon_list.append(['2b_2b', reverse_complement(seq_2b) + seq_2b])\n",
    "    elif reaction_type == 'triple_cut_different_chromosomes':\n",
    "        # Case three guides on different chromosomes\n",
    "\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_3'] == '+':\n",
    "            cut3 = amplicon_info['end_guide_3'] - 3\n",
    "        elif amplicon_info['strand_guide_3'] == '-':\n",
    "            cut3 = amplicon_info['start_guide_3'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_3 can only have as values + or -')\n",
    "\n",
    "        start_coordinate1 = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate1 < 0:\n",
    "            start_coordinate1 = 0\n",
    "        end_coordinate1 = int(cut1 + amplicon_window_around_cut)\n",
    "        if end_coordinate1 > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate1 = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        start_coordinate2 = int(cut2 - amplicon_window_around_cut)\n",
    "        if start_coordinate2 < 0:\n",
    "            start_coordinate2 = 0\n",
    "        end_coordinate2 = int(cut2 + amplicon_window_around_cut)\n",
    "        if end_coordinate2 > len(genome[amplicon_info['chr_guide_2']]):\n",
    "            end_coordinate2 = len(genome[amplicon_info['chr_guide_2']])\n",
    "\n",
    "        start_coordinate3 = int(cut3 - amplicon_window_around_cut)\n",
    "        if start_coordinate3 < 0:\n",
    "            start_coordinate3 = 0\n",
    "        end_coordinate3 = int(cut3 + amplicon_window_around_cut)\n",
    "        if end_coordinate3 > len(genome[amplicon_info['chr_guide_3']]):\n",
    "            end_coordinate3 = len(genome[amplicon_info['chr_guide_3']])\n",
    "\n",
    "        seq_1a = genome[amplicon_info['chr_guide_1']][start_coordinate1:int(cut1)]\n",
    "        seq_1b = genome[amplicon_info['chr_guide_1']][int(cut1):end_coordinate1]\n",
    "        seq_2a = genome[amplicon_info['chr_guide_2']][start_coordinate2:int(cut2)]\n",
    "        seq_2b = genome[amplicon_info['chr_guide_2']][int(cut2):end_coordinate2]\n",
    "        seq_3a = genome[amplicon_info['chr_guide_3']][start_coordinate3:int(cut3)]\n",
    "        seq_3b = genome[amplicon_info['chr_guide_3']][int(cut3):end_coordinate3]\n",
    "\n",
    "        amplicon_list.append(['1a_1a', seq_1a + reverse_complement(seq_1a)])\n",
    "        amplicon_list.append(['1a_1b', seq_1a + seq_1b])\n",
    "        amplicon_list.append(['1a_2a', seq_1a + reverse_complement(seq_2a)])\n",
    "        amplicon_list.append(['1a_2b', seq_1a + seq_2b])\n",
    "        amplicon_list.append(['1a_3a', seq_1a + reverse_complement(seq_3a)])\n",
    "        amplicon_list.append(['1a_3b', seq_1a + seq_3b])\n",
    "\n",
    "        amplicon_list.append(['1b_1b', reverse_complement(seq_1b) + seq_1b])\n",
    "        amplicon_list.append(['2a_1b', seq_2a + seq_1b])\n",
    "        amplicon_list.append(['2b_1b', reverse_complement(seq_2b) + seq_1b])\n",
    "        amplicon_list.append(['3a_1b', seq_3a + seq_1b])\n",
    "        amplicon_list.append(['3b_1b', reverse_complement(seq_3b) + seq_1b])\n",
    "\n",
    "        amplicon_list.append(['2a_2a', seq_2a + reverse_complement(seq_2a)])\n",
    "        amplicon_list.append(['2a_2b', seq_2a + seq_2b])\n",
    "        amplicon_list.append(['2a_3a', seq_2a + reverse_complement(seq_3a)])\n",
    "        amplicon_list.append(['2a_3b', seq_2a + seq_3b])\n",
    "\n",
    "        amplicon_list.append(['2b_2b', reverse_complement(seq_2b) + seq_2b])\n",
    "        amplicon_list.append(['3a_2b', seq_3a + seq_2b])\n",
    "        amplicon_list.append(['3b_2b', reverse_complement(seq_3b) + seq_2b])\n",
    "\n",
    "        amplicon_list.append(['3a_3a', seq_3a + reverse_complement(seq_3a)])\n",
    "        amplicon_list.append(['3a_3b', seq_3a + seq_3b])\n",
    "\n",
    "        amplicon_list.append(['3b_3b', reverse_complement(seq_3b) + seq_3b])\n",
    "        \n",
    "    write_amplicon(dir_sample, amplicon_info, amplicon_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the amplicons by calling the create_amplicon function\n",
    "assembly = amplicon_info['genome']\n",
    "file_genome_2bit = os.path.join('/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes', assembly + '.2bit')\n",
    "\n",
    "create_amplicon(directory10000, amplicon_info10000, file_genome_2bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_plasmid_local(dir_sample, amplicon_info, ncpu=4):\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    # exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "\n",
    "    file_cutadapt_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "    file_cutadapt_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "\n",
    "    file_sam_plasmid_local = create_filename(dir_sample, N7, N5, 'sam_plasmid_local')\n",
    "    file_sam_report_plasmid_local = create_filename(dir_sample, N7, N5, 'sam_report_plasmid_local')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_sam_plasmid_local)):\n",
    "        os.mkdir(os.path.dirname(file_sam_plasmid_local))\n",
    "\n",
    "    file_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'bam_plasmid_local')\n",
    "    file_sorted_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'sorted_bam_plasmid_local')\n",
    "    # file_sorted_bai_genome_local = create_filename(dir_sample, N7, N5, 'sorted_bai_genome_local')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_bam_plasmid_local)):\n",
    "        os.mkdir(os.path.dirname(file_bam_plasmid_local))\n",
    "\n",
    "    # local alignment to the genome with bowtie2\n",
    "    initial_dir = os.getcwd()\n",
    "\n",
    "    folder_amplicons = create_filename(dir_sample, N7, N5, 'amplicons')\n",
    "\n",
    "    os.chdir(folder_amplicons)\n",
    "\n",
    "    bowtie2_command = ['bowtie2', '--local', '-p', str(ncpu),\n",
    "                       '-X', '5000', '-k', '2', '-x', 'plasmid',\n",
    "                             '-1', file_cutadapt_R1, '-2', file_cutadapt_R2,\n",
    "                             '-S', file_sam_plasmid_local]\n",
    "\n",
    "    handle_sam_report_genome_local = open(file_sam_report_plasmid_local, 'wb')\n",
    "\n",
    "    subprocess.call(bowtie2_command, stderr=handle_sam_report_genome_local)\n",
    "\n",
    "    handle_sam_report_genome_local.close()\n",
    "\n",
    "    # convert sam to bam\n",
    "    sam_to_bam_plasmid_local_command = ['samtools', 'view', '-Sb', file_sam_plasmid_local]\n",
    "\n",
    "    handle_file_bam_plasmid_local = open(file_bam_plasmid_local, 'wb')\n",
    "\n",
    "    subprocess.call(sam_to_bam_plasmid_local_command, stdout=handle_file_bam_plasmid_local)\n",
    "\n",
    "    # sort bam files\n",
    "    sort_bam_plasmid_local_command = ['samtools', 'sort', file_bam_plasmid_local, '-o', file_sorted_bam_plasmid_local]\n",
    "\n",
    "    subprocess.call(sort_bam_plasmid_local_command)\n",
    "\n",
    "    # Create bam index files\n",
    "    create_bam_plasmid_local_index_command = ['samtools', 'index', file_sorted_bam_plasmid_local]\n",
    "    subprocess.call(create_bam_plasmid_local_index_command)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(file_sam_plasmid_local)\n",
    "    os.remove(file_bam_plasmid_local)\n",
    "\n",
    "    os.chdir(initial_dir)\n",
    "\n",
    "def extract_unmapped_reads_plasmid(dir_sample, amplicon_info):\n",
    "\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    file_sorted_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'sorted_bam_plasmid_local')\n",
    "\n",
    "    file_unmapped_bam_plasmid = create_filename(dir_sample, N7, N5, 'unmapped_bam_plasmid_local')\n",
    "\n",
    "    file_qsorted_unmapped_bam_plasmid = create_filename(dir_sample, N7, N5, 'qsorted_unmapped_bam_plasmid_local')\n",
    "\n",
    "    file_R1_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R1fastq')\n",
    "    file_R2_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R2fastq')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_R1_unmapped)):\n",
    "        os.mkdir(os.path.dirname(file_R1_unmapped))\n",
    "\n",
    "    extract_unmapped_bam_command = ['samtools', 'view', '-b', '-f', '0x4', file_sorted_bam_plasmid_local, '-o',\n",
    "                                    file_unmapped_bam_plasmid]\n",
    "\n",
    "    subprocess.call(extract_unmapped_bam_command)\n",
    "\n",
    "    qsort_unmapped_bam_command = ['samtools', 'sort', '-n', file_unmapped_bam_plasmid, '-o',\n",
    "                                  file_qsorted_unmapped_bam_plasmid]\n",
    "\n",
    "    subprocess.call(qsort_unmapped_bam_command)\n",
    "\n",
    "    bamtofastq_command = ['bedtools', 'bamtofastq', '-i', file_qsorted_unmapped_bam_plasmid,\n",
    "                          '-fq', file_R1_unmapped, '-fq2', file_R2_unmapped]\n",
    "\n",
    "    file_err = file_R1_unmapped[:-9] + '_err.txt'\n",
    "    handle_file_err = open(file_err, 'wb')\n",
    "\n",
    "    subprocess.call(bamtofastq_command, stderr=handle_file_err)\n",
    "\n",
    "    for fo in [file_R1_unmapped, file_R2_unmapped]:\n",
    "        with open(fo) as f_in, gzip.open(fo + '.gz', 'wb') as f_out:\n",
    "            f_out.writelines(f_in)\n",
    "        os.remove(fo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out the alignment to the plasmid\n",
    "align_plasmid_local(directory10000, amplicon_info10000, ncpu=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the unmapped reads\n",
    "extract_unmapped_reads_plasmid(directory10000, amplicon_info10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze plasmid alignments\n",
    "\n",
    "def analyze_alignments_plasmid(dir_sample, amplicon_info, min_MAPQ, file_genome_2bit, do_plasmid):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "        \n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "\n",
    "    file_UMI = create_filename(dir_sample, N7, N5, 'umifastqgz')\n",
    "    UMI_dict = create_barcode_dict(file_UMI)\n",
    "    \n",
    "    results_folder = os.path.join(exp_dir, 'results')\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "\n",
    "    results_file = create_filename(dir_sample, N7, N5, 'results_plasmid')\n",
    "\n",
    "    if do_plasmid:\n",
    "        file_sorted_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'sorted_bam_plasmid_local')\n",
    "\n",
    "        bam_in_alignment_file = pysam.AlignmentFile(file_sorted_bam_plasmid_local, 'rb')\n",
    "        bam_in = bam_in_alignment_file.fetch()\n",
    "\n",
    "        genome = twobitreader.TwoBitFile(file_genome_2bit)  # Load genome. Used for getting the sequences\n",
    "        \n",
    "        length_to_test = 15  # We check this number of bases after the primer\n",
    "        uditas_primer_length = amplicon_info['end'] - amplicon_info['start']\n",
    "        \n",
    "        if amplicon_info['strand'] == '+':  # This is the UDiTaS oligo strand\n",
    "            #I had to add int() command to make this work for some reason\n",
    "            seq_after_uditas_primer = genome[amplicon_info['chr']][int(amplicon_info['end']):int((amplicon_info['end'] + length_to_test))]\n",
    "            \n",
    "        elif amplicon_info['strand'] == '-':\n",
    "            seq_after_uditas_primer = reverse_complement(genome[amplicon_info['chr']][(amplicon_info['start'] - length_to_test):amplicon_info['start']])\n",
    "        n_max_mismatches = 2  # We allow this number of mismatches between the read and the sequence after the primer\n",
    "\n",
    "        names_list_plasmid_genome = []\n",
    "        UMI_list_plasmid_genome = []\n",
    "        names_list_plasmid_only = []\n",
    "        UMI_list_plasmid_only = []\n",
    "\n",
    "        for read in bam_in:\n",
    "            if read.mapping_quality >= min_MAPQ and not read.is_unmapped and not read.is_secondary:\n",
    "                if read.is_read2:  # R2 is the UDiTaS primer\n",
    "                    if read.is_reverse:\n",
    "                        seq_test = reverse_complement(read.query_sequence)[uditas_primer_length:(uditas_primer_length + length_to_test)]\n",
    "                    else:\n",
    "                        seq_test = read.query_sequence[uditas_primer_length:(uditas_primer_length + length_to_test)]\n",
    "\n",
    "                    # Sometimes, after cutadapt we have a read shorter than uditas_primer_length + length_to_test\n",
    "                    # We skip those directly without calculating hamm_dist, which doesn't make sense\n",
    "                    if (len(seq_test) == len(seq_after_uditas_primer.upper()) and\n",
    "                        hamm_dist(seq_test, seq_after_uditas_primer.upper()) <= n_max_mismatches):\n",
    "                        # Reads for which the R2 has genomic sequence after the UDiTaS primer\n",
    "                        UMI_list_plasmid_genome.append(UMI_dict[read.query_name][0])\n",
    "                        names_list_plasmid_genome.append(read.query_name)\n",
    "                    else: # We put those short reads into the plasmid only bucket\n",
    "                        UMI_list_plasmid_only.append(UMI_dict[read.query_name][0])\n",
    "                        names_list_plasmid_only.append(read.query_name)\n",
    "\n",
    "        total_reads_plasmid_genome = len(set(names_list_plasmid_genome))\n",
    "        total_reads_collapsed_plasmid_genome = len(set(UMI_list_plasmid_genome))\n",
    "        total_reads_plasmid_only = len(set(names_list_plasmid_only))\n",
    "        total_reads_collapsed_plasmid_only = len(set(UMI_list_plasmid_only))\n",
    "\n",
    "        results_df = pd.DataFrame({'target_plus_plasmid_total_reads': [total_reads_plasmid_genome],\n",
    "                                   'target_plus_plasmid_total_reads_collapsed': [total_reads_collapsed_plasmid_genome],\n",
    "                                   'plasmid_only_total_reads': [total_reads_plasmid_only],\n",
    "                                   'plasmid_only_total_reads_collapsed': [total_reads_collapsed_plasmid_only]\n",
    "                                   },\n",
    "                                  columns=['target_plus_plasmid_total_reads',\n",
    "                                           'target_plus_plasmid_total_reads_collapsed',\n",
    "                                           'plasmid_only_total_reads',\n",
    "                                           'plasmid_only_total_reads_collapsed'])\n",
    "    else:\n",
    "        results_df = pd.DataFrame(index=np.arange(1),\n",
    "                                  columns=['target_plus_plasmid_total_reads',\n",
    "                                           'target_plus_plasmid_total_reads_collapsed',\n",
    "                                           'plasmid_only_total_reads',\n",
    "                                           'plasmid_only_total_reads_collapsed'])\n",
    "\n",
    "    results_df.to_excel(results_file)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "#################################################################################\n",
    "# Function to create barcode dict\n",
    "#################################################################################\n",
    "def create_barcode_dict(filename):\n",
    "    barcode_file = open_fastq_or_gz(filename)\n",
    "\n",
    "    barcode_dict = dict()\n",
    "\n",
    "    barcode_reads = itertools.izip(barcode_file)\n",
    "\n",
    "    for header_barcode in barcode_reads:\n",
    "        seq_barcode = barcode_reads.next()\n",
    "        barcode_reads.next()\n",
    "        qual_barcode = barcode_reads.next()\n",
    "        barcode_dict[header_barcode[0].split()[0][1:]] = [seq_barcode[0].rstrip(), qual_barcode[0].rstrip()]\n",
    "\n",
    "    return barcode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tggcatgaacctgggaggcagagcttgcagtgagccaagatcatgccactgcactccaggctgggtgacagagcgagactccgtctcaaaaaaaaaaaaa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_plus_plasmid_total_reads</th>\n",
       "      <th>target_plus_plasmid_total_reads_collapsed</th>\n",
       "      <th>plasmid_only_total_reads</th>\n",
       "      <th>plasmid_only_total_reads_collapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_plus_plasmid_total_reads  target_plus_plasmid_total_reads_collapsed  \\\n",
       "0                                0                                          0   \n",
       "\n",
       "   plasmid_only_total_reads  plasmid_only_total_reads_collapsed  \n",
       "0                         0                                   0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the plasmid analysis to coudn plasmid integration events\n",
    "analyze_alignments_plasmid(directory10000, amplicon_info10000, 5, file_genome_2bit, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#\n",
    "# Aligns reads globally to amplicon.\n",
    "# Input: directory to be analyzed\n",
    "#        amplicon_info, slice of sample_info.csv for the sample being processed\n",
    "#        file_genome_2bit, 2bit file with the reference genome being used\n",
    "#\n",
    "# ##########################\n",
    "def align_amplicon(dir_sample, amplicon_info, check_plasmid_insertions, ncpu=4):\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    has_plasmid = type(amplicon_info['plasmid_sequence']) is str or type(amplicon_info['plasmid_sequence']) is unicode\n",
    "\n",
    "    if check_plasmid_insertions == 1 and has_plasmid:\n",
    "        file_R1 = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R1fastqgz')\n",
    "        file_R2 = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R2fastqgz')\n",
    "    else:\n",
    "        file_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "        file_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_R1)):\n",
    "        os.mkdir(os.path.dirname(file_R1))\n",
    "\n",
    "    file_sam_amplicons = create_filename(dir_sample, N7, N5, 'sam_amplicons')\n",
    "    file_sam_report_amplicons = create_filename(dir_sample, N7, N5, 'sam_report_amplicons')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_sam_amplicons)):\n",
    "        os.mkdir(os.path.dirname(file_sam_amplicons))\n",
    "\n",
    "    file_bam_amplicons = create_filename(dir_sample, N7, N5, 'bam_amplicons')\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_bam_amplicons)):\n",
    "        os.mkdir(os.path.dirname(file_bam_amplicons))\n",
    "\n",
    "    # global alignment to the amplicons with bowtie2\n",
    "    initial_dir = os.getcwd()\n",
    "    folder_amplicons = create_filename(dir_sample, N7, N5, 'amplicons')\n",
    "\n",
    "    os.chdir(folder_amplicons)\n",
    "    bowtie2_command = ['bowtie2', '-p', str(ncpu), '--very-sensitive',\n",
    "                       '-X', '5000', '-k', '2', '-x', 'amplicons',\n",
    "                       '-1', file_R1, '-2', file_R2,\n",
    "                       '-S', file_sam_amplicons]\n",
    "\n",
    "    handle_sam_report_amplicons = open(file_sam_report_amplicons, 'wb')\n",
    "\n",
    "    subprocess.call(bowtie2_command, stderr=handle_sam_report_amplicons)\n",
    "\n",
    "    handle_sam_report_amplicons.close()\n",
    "\n",
    "    # convert sam to bam\n",
    "    sam_to_bam_amplicons_command = ['samtools', 'view', '-Sb', file_sam_amplicons]\n",
    "\n",
    "    handle_file_bam_amplicons = open(file_bam_amplicons, 'wb')\n",
    "\n",
    "    subprocess.call(sam_to_bam_amplicons_command, stdout=handle_file_bam_amplicons)\n",
    "\n",
    "    # sort bam files\n",
    "    sort_bam_amplicons_command = ['samtools', 'sort', file_bam_amplicons, '-o', file_sorted_bam_amplicons]\n",
    "\n",
    "    subprocess.call(sort_bam_amplicons_command)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(file_sam_amplicons)\n",
    "    os.remove(file_bam_amplicons)\n",
    "\n",
    "    # Create bam index files\n",
    "    create_bam_amplicons_index_command = ['samtools', 'index', file_sorted_bam_amplicons]\n",
    "    subprocess.call(create_bam_amplicons_index_command)\n",
    "\n",
    "    os.chdir(initial_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align against our suite of amplicons\n",
    "align_amplicon(directory10000, amplicon_info10000, 1, ncpu=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Function to extract all unmapped reads to the amplicons\n",
    "################################################################################\n",
    "def extract_unmapped_reads_amplicons(dir_sample, amplicon_info):\n",
    "\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    file_unmapped_bam_amplicons = create_filename(dir_sample, N7, N5, 'unmapped_bam_amplicons')\n",
    "\n",
    "    file_qsorted_unmapped_bam_amplicons = create_filename(dir_sample, N7, N5, 'qsorted_unmapped_bam_amplicons')\n",
    "\n",
    "    file_R1_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_R1fastq')\n",
    "    file_R2_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_R2fastq')\n",
    "    file_unmapped_report = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_report')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_R1_unmapped)):\n",
    "        os.mkdir(os.path.dirname(file_R1_unmapped))\n",
    "\n",
    "    extract_unmapped_bam_command = ['samtools', 'view', '-b', '-f', '0x4', file_sorted_bam_amplicons, '-o',\n",
    "                                    file_unmapped_bam_amplicons]\n",
    "\n",
    "    subprocess.call(extract_unmapped_bam_command)\n",
    "\n",
    "    qsort_unmapped_bam_command = ['samtools', 'sort', '-n', file_unmapped_bam_amplicons, '-o',\n",
    "                                  file_qsorted_unmapped_bam_amplicons]\n",
    "\n",
    "    subprocess.call(qsort_unmapped_bam_command)\n",
    "\n",
    "    bamtofastq_command = ['bedtools', 'bamtofastq', '-i', file_qsorted_unmapped_bam_amplicons,\n",
    "                          '-fq', file_R1_unmapped, '-fq2', file_R2_unmapped]\n",
    "\n",
    "    handle_unmapped_report = open(file_unmapped_report, 'wb')\n",
    "    subprocess.call(bamtofastq_command, stderr=handle_unmapped_report)\n",
    "\n",
    "    for fo in [file_R1_unmapped, file_R2_unmapped]:\n",
    "        with open(fo) as f_in, gzip.open(fo + '.gz', 'wb') as f_out:\n",
    "            f_out.writelines(f_in)\n",
    "        os.remove(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will bring the files that did not map to amplicons into a new folder\n",
    "extract_unmapped_reads_amplicons(directory10000, amplicon_info10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
